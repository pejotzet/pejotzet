[
  
  {
    "title": "Budowanie aplikacji dla SBC w środowisku emulowanym",
    "url": "/posts/emulated-building-for-SBC/",
    "categories": "",
    "tags": "C/C++, SBC, Docker, DevContainers, QEMU",
    "date": "2023-08-13 09:58:41 +0200",
    





    
    "snippet": "Komputery jednopłytkowe (ang. SBC — Single Board Computer) to uniwersalne urządzenia mikroprocesorowe pracujące pod kontrolą systemu operacyjnego.Zazwyczaj systemem tym jest Linux.Architektury komp...",
    "content": "Komputery jednopłytkowe (ang. SBC — Single Board Computer) to uniwersalne urządzenia mikroprocesorowe pracujące pod kontrolą systemu operacyjnego.Zazwyczaj systemem tym jest Linux.Architektury komputerów jednopłytkowych mogą istotnie się różnić od architektur stosowanych dla komputerów osobistych.Niestety natywne uruchamianie kodu z wykorzystaniem GUI pracującego na systemie target jest często niewykonalne, głównie ze względu na ograniczony interfejs użytkownika i niezbyt duże zasoby urządzenia.Zazwyczaj problem ten rozwiązuje się przy użyciu narzędzi do kompilacji skrośnej.W niniejszym opracowaniu przedstawiono podejście alternatywne bazujące na wykorzystaniu emulacji architektury urządzenia docelowego z wykorzystaniem QEMU i połączonej z hermetyzacją środowiska developerskiego w kontenerze Docker’a.Dzięki tej technice możliwe jest wygenerowanie kodu binarnego dla urządzenia docelowego bez korzystania z technik kompilacji skrośnej.Jako frontend dewelopera zaproponowano wykorzystanie programu VS Code oraz techniki DevContainers.Stworzenie środowiska pracy skrośnej jest zadaniem żmudnym, zwłaszcza jeżeli w systemie muszą współegzystować środowiska przeznaczone dla różnych urządzeń docelowych. Oczywiście ideałem byłoby środowisko pracy natywnej na urządzeniu target, jednak opcja ta jest często niemożliwa do realizacji praktycznej ze względu na jego ograniczone zasoby.Okazuje się, że konteneryzacja w połączeniu z emulacją architektury pozwala na stworzenia środowiska budowy aplikacji bardzo zbliżonego tego ideału.Przedstawiona dalej konfiguracja bardzo przypominapracę zdalną w tunelu SSH [1],jednak tym razem urządzenie docelowe nie jest w zaangażowane w proces budowania aplikacji.Oczywiście jest ono niezbędne do jej debugowania.Proces skrośnego debugowania opisano w podrozdziale “Uruchamianie skrośne” wspomnianego wcześniej opracowania [1].Realizacja przedstawionego dalej scenariusza wymaga zainstalowania na systemie host Docker‘a i opcjonalnie QEMU.Pozostałe oprogramowanie zostanie umieszczone w kontenerach i może być łatwo usunięte z systemu jednym poleceniem.      QEMUto dostępne nieodpłatnie środowisko wirtualizacji systemów oraz dynamicznej emulacji architektur. Pierwsza opcja zapewnia możliwość uruchomienia pełnego systemu operacyjnego na wirtualnym urządzeniu. Innymi słowy, wirtualizator zapewnia abstrakcyjną warstwę dostępu do sprzętu. Szczególną cechą QEMU jest możliwość wirtualizacji systemów dla architektur innych niż architektura systemu goszczącego (popularne hypervisory takie jak VirtualBox, VMWare Workstation czy Hyper-V tego nie potrafią).Z kolei dynamiczna emulacja polega na tłumaczeniu w locie kodu binarnego z architektury systemu emulowanego na architekturę systemu goszczącego. Aplikacje uruchamiane w tym trybie korzystają bezpośrednio z jądra systemu goszczącego, w tym sprzętu dostępnego na tym systemie.Z punktu widzenia użytkownika, aplikacje uruchomione w tym trybie wyglądają identycznie jak aplikacje natywne, jedynie wykonują się wolniej ze względu na niezbędną warstwę translacji.        Dockerto środowisko konteneryzacji zapewniające aplikacjom hermetyczne środowisko pracy (dostęp do usług jądra systemu, środowisko sieciowe, system plików), co umożliwia ich bezproblemową dystrybucję i pracę niezależnie od systemu operacyjnego gospodarza.W połączeniu z emulacją architektur zapewnianą przez QEMU możliwe jest uruchamianie i budowanie kontenerów na architekturę inną niż ta, na której uruchomiony jest Docker.  Idea budowy aplikacji z wykorzystaniem emulacji architektury zakłada      uruchomienie emulacji architektury systemu target (tego, na którym ma działać aplikacja) na systemie host (tego, na którym zostanie skompilowana),        przygotowanie kontenera dla architektury target, który zawiera jego główny system plików uzupełniony o natywne dla target narzędzia budowania aplikacji (kompilator, linker, biblioteki),        uruchomienie w emulowanym kontenerze kompilacji natywnej (czyli dla architektury target).  Aktywacja emulacji architektury systemu targetW systemie host konieczna jest aktywacja emulacji architektury systemu target.Można to osiągnąć, instalując pakiet qemu-user-staticapt install -y qemu-user-staticAlternatywnie, można skorzystać z gotowego konteneradocker run --rm --privileged multiarch/qemu-user-static:register --resetListę emulowanych architektur zwraca komendals  /proc/sys/fs/binfmt_miscPrzygotowanie kontenera dla architektury systemu targetW pustym katalogu należy umieścić archiwum z głównym systemem plików urządzenia target.Archiwum można utworzyć, pobierając, z zachowaniem uprawnień, pliki z karty SD zawierającej firmware urządzenia target (w poniższym przykładzie przyjęto, że po zamontowaniu w systemie host zawartość karty jest widoczna w katalogu ‘/media/akuku/a6a42a97-600f-4ed7-ab06-6a2a169c62f3/’).Archiwum ‘rootfs.tar’ buduje komenda(cd /media/akuku/a6a42a97-600f-4ed7-ab06-6a2a169c62f3/ ; sudo tar cvf - *) | cat &gt; ./rootfs.tarInspekcja zawartości archiwum komendą tar tf rootfs.tar | head -n 10 powinna wykazać wynik podobny do poniższego (brak dodatkowych elementów przed ‘bin’, ‘boot’, itd.)binboot/boot/boot.cmdboot/orangepi_first_run.txt.templateboot/boot.scrboot/orangepiEnv.txtboot/vmlinuz-4.9.170-sun50iw9boot/config-4.9.170-sun50iw9boot/uInitrdboot/boot.bmpZgodnie z zasadą *wszystko można, co nie można, byle z wolna i ostrożna*, główny system plików można również pobrać z działającego urządzenia.W tym samym katalogu należy utworzyć plik Dockerfile o treściFROM scratchARG USERNAME=orangepiARG USER_UID=1000ARG USER_GID=1000ADD rootfs.tar /USER rootWORKDIR /rootRUN apt-get update &amp;&amp; export DEBIAN_FRONTEND=noninteractive \\    &amp;&amp; apt-get -y install build-essential make gpiodENV HOME=/home/${USERNAME}# [Optional] Customize environment for nonroot user#RUN groupadd --gid \"${USER_GID}\" \"${USERNAME}\" &amp;&amp; \\#    useradd --uid \"${USER_UID}\" --gid \"${USER_GID}\" --create-home \"${USERNAME}\" &amp;&amp; \\#    apt-get update &amp;&amp; \\#    apt-get -yq install sudo &amp;&amp; \\#    echo \"${USERNAME}\" ALL=\\(root\\) NOPASSWD:ALL &gt; \"/etc/sudoers.d/${USERNAME}\" &amp;&amp; \\#    chmod 0440 \"/etc/sudoers.d/${USERNAME}\" #    &amp;&amp; \\#    usermod -aG docker \"${USERNAME}\"WORKDIR ${HOME}USER ${USERNAME}CMD uname -aKompilacja w kontenerze pozostawia pliki binarne w katalogu projektu.Właścicielem tych plików jest użytkownik (określony w kontenerze, tutaj orangepi), w którego imieniu została wykonana kompilacja. Zatem, aby uniknąć kłopotów z dostępem do plików, należy zadbać o to, aby UID i GID użytkownika systemu host i użytkownika w kontenerze były takie same. Wartości te sprawdza się poleceniem id wydanym w terminalu. W powyższym przykładzie przyjęto, że zarówno użytkownik ‘akuku’ systemu host oraz użytkownik ‘orangepi’ zdefiniowany w kontenerze mają UID i GID równe 1000.Przedstawiony powyżej plik definiuje sposób budowy kontenera.Przed jej uruchomieniem należy sprawdzić, czy jest ona możliwadocker buildx lsdocker buildx use defaultJeżeli docelowa platforma jest na liście, to do zbudowania kontenera wystarczy poniższa komendadocker buildx build --platform linux/arm64 -t pzawad/orangepi-emucontainer .wydana w katalogu zawierającym pliki ‘Dockerfile’ i ‘rootfs.tar’.Architekturę zbudowanego kontenera, wersję systemu operacyjnego oraz dostępność kompilatora należy oczywiście sprawdzićdocker image inspect pzawad/orangepi-emucontainer | grep Architecturedocker run -it --rm pzawad/orangepi-emucontainer bash -c 'uname -a'docker run -it --rm pzawad/orangepi-emucontainer bash -c 'cat /etc/issue'docker run -it --rm pzawad/orangepi-emucontainer bash -c 'gcc -v'Kompilacja emulowana z wykorzystaniem konteneraKontener z narzędziami dla architektury docelowej pozwala na skompilowanie na systemie host kodu dla systemu target w trybie kompilacji natywnej.Katalog ze źródłami aplikacji jest mapowany do wnętrza kontenera, w którym wywoływany jest kompilator natywny dla platformy docelowej. Kompilator “widzi” kopię głównego systemu plików urządzenia target, dzięki czemu wszystkie pliki nagłówkowe i biblioteki dynamiczne są na właściwym miejscu.Komenda realizująca kompilację ma np. postaćdocker run -it --rm --platform=linux/arm64 --name omgthisworks -v ${PWD}:/home/orangepi pzawad/orangepi-emucontainer makeIntegracja z Visual Studio Code nie nastręcza trudności.Do pliku ‘.vscode/tasks.json’ wystarczy dodać zadanie postaci{  \"version\": \"2.0.0\",  \"tasks\": [    {      \"label\": \"Native Build in container\",      \"type\": \"shell\",      \"command\": \" docker run -it --rm --platform=linux/arm64 --name omgthisworks -v ${workspaceFolder}:/home/orangepi pzawad/orangepi-emucontainer make\",      \"group\": {        \"isDefault\": true,        \"kind\": \"build\"      },      \"options\": {        \"cwd\": \"${workspaceFolder}\"      },      \"problemMatcher\": [          \"$gcc\"      ],      \"detail\": \"This task maps workspace into container and triggers native build inside.\"    }  ]}Debugowanie kodutestPodsumowanieZaletą opisanego podejścia jest prawidłowe dynamiczne łączenie bibliotek bez żadnych dodatkowych zabiegów.Co więcej, nie jest konieczna instalacja narzędzi do kompilacji ani na systemie target, ani na systemie host. Kontener służący do tworzenia aplikacji może być łatwo dystrybuowany pomiędzy programistami. W efekcie procedurę przygotowania kontenera zawierającego oprogramowanie niezbędne do pracy nad aplikacja wystarczy przeprowadzić tylko raz. Ma to olbrzymie znaczenie w pracy grupowej gdzie hermetyczność narzędzi i powtarzalność procedur mają ogromne znaczenie.Bibliografia[1] PeJotZet “Jak kompilować i debugować aplikacje w C/C++ na komputery jednopłytkowe korzystając z VS Code”, 2023Kruczki i sztuczkiZdalny dostęp do konta administratora bez podawania hasła      Zdalny dostęp do konta administratora    W pliku /etc/ssh/sshd_config’ (target) należy ustawić opcję     PermitRootLogin   yes            Logowanie bez konieczności podawania hasła                  Serwer ssh musi zezwalać na uwierzytelnienie za pomocą kluczy publicznych.W pliku /etc/ssh/sshd_config’ (target) należy ustawić opcje        PubkeyAuthentication   yesAuthorizedKeysFile    .ssh/authorized_keys    .ssh/authorized_keys2                            Użytkownik systemu host musi mieć wygenerowane osobiste klucze ssh. Generacja komendą        ssh-keygen                Opcją ‘-t’ można wymusić typ klucza, a opcją ‘-b’ jego długość. Wygenerowane klucze, prywatny i publiczny, umieszczone są w podkatalogu ‘.ssh’ katalogu domowego (publiczny ma rozszerzenie ‘pub’).                    Klucz publiczny należy umieścić na systemie target w pliku ‘.ssh/authorized_keys’ nakoncie docelowym. Wygodne kopiowanie zapewnia komenda (poniżej użyto konta root)        ssh-copy-id root@opi.usb                    Pobranie głównego systemu plików z działającego urządzeniaJeżeli główny system plików archiwizujemy z działającego urządzenia target, to przed operacją archiwizacji katalog główny należy zamontować w innym miejscu przy użyciu ‘mount –bind’ i dopiero w nim wydać komendę archiwizacji. Wynik archiwizacji najlepiej od razu pobrać na system hostssh root@opi.usb 'mkdir -p /tmp/rootfs &amp;&amp; mount --bind / /tmp/rootfs &amp;&amp; cd /tmp/rootfs/ &amp;&amp; tar cf - *' &gt; rootfs.tarW powyższej komendzie opi.usb to nazwa sieciowa urządzenia target i może być zastąpiona przez jego numer IP."
  },
  
  {
    "title": "Jak uruchamiać programy dla ESP32 korzystając z ESP-Prog",
    "url": "/posts/how-to-debug-esp32-with-esp-prog/",
    "categories": "",
    "tags": "Code, PlatformIO, ESP32, ESP-Prog",
    "date": "2023-08-12 15:13:20 +0200",
    





    
    "snippet": "ESP-Prog jest programatorem i debuggerem do platformy ESP32.Niniejszy dokument opisuje jak korzystać z tego urządzenia w systemie Linux z zainstalowanym edytorem Code wyposażonym w rozszerzenie Pla...",
    "content": "ESP-Prog jest programatorem i debuggerem do platformy ESP32.Niniejszy dokument opisuje jak korzystać z tego urządzenia w systemie Linux z zainstalowanym edytorem Code wyposażonym w rozszerzenie PlatformIO.Anatomia ESP-ProgPłyta ESP-Prog jest wyposażona w dwa złącza służące do komunikacji z urządzeniem docelowym.Złącze PROG służy do wgrania nowej wersji firmware’u na urządzenie docelowe, natomiast złącze JTAG umożliwia krokowe wykonanie programu, inspekcję pamięci urządzenia itp.Do pinów złącz przypisane są następujące sygnały    Podłączenie obu interfejsów do urządzenia docelowego powoduje, że ESP-Prog przejmuje nad nim pełną kontrolę.W takim podejściu jedynym urządzeniem komunikującym się z komputerem PC jest ESP-Prog.W drugiej wersji konfiguracji z urządzeniem docelowym łączymy tylko sygnały ze złącza JTAG.Do aktualizacji firmware’u wykorzystywany jest wtedy natywny interfejs urządzenia docelowego, natomiast złącze JTAG służy tylko i wyłącznie do kontroli wykonywanego kodu.Na koniec kilka uwag nt. zasilania urządzenia docelowego.Obok złącz znajdują się trójpinowe zworki.Ich odpowiednie zwarcie ustawia żądany poziom napięcia na pinie VDD każdego ze złącz.Napięcie 3.3V jest brane z wyjścia regulatora na ESP-Prog i może być połączone z pinem 3.3V na płycie docelowej.Natomiast napięcie 5V pochodzi bezpośrednio ze złącza USB (sprzed regulatora) i musi być łączone z pinem 5V na płycie docelowej.Zadanie stabilizacji napięcia 3.3V na płycie docelowej przejmie wtedy jej własny regulator.Oczywiście, nie ma wtedy potrzeby łączenia 3.3V z ESP-Prog z płytą docelową.Warto zauważyć, że łączenie napięć można zupełnie pominąć i zasilić urządzenie docelowe z niezależnego źródła np. ładowarki telefonu.Oczywiście masy urządzeń powinny być obowiązkowo połączone.Szczegółowy opis właściwości układu jest dostępny na jego stronie domowej [1].Przygotowanie systemu LinuxPrzygotowanie systemu przebiega dokładnie tak samo, jak w przypadku pracy z dowolnym mikrokontrolerem opartym o układ ESP32.Po podłączeniu takiego mikrokontrolera w systemie pojawiają się urządzenia /dev/ttyUSBx, gdzie x należy zastąpić numerem kolejnego urządzenia.Konfiguracja systemu sprowadza się do nadania praw dostępu do tych urządzeń nieuprzywilejowanym użytkownikom.Dostęp dla wszystkich użytkownikówInstalacja odpowiednich reguł dla demona udev zapewnia dostęp world-wide do plików tworzonych przez sterowniki urządzeń USB o identyfikatorach przypisanych emulatorom łącza szeregowego.curl -fsSL https://raw.githubusercontent.com/platformio/platformio-core/develop/platformio/assets/system/99-platformio-udev.rules | sudo tee /etc/udev/rules.d/99-platformio-udev.rulessudo udevadm control --reload-rulessudo udevadm triggerDostęp tylko dla wybranych użytkownikówBardziej subtelna kontrola dostępu wykorzystuje mechanizm przynależności użytkowników systemu do odpowiednich grup.Domyślnie pliki /dev/ttyUSBx mają prawa dostępu postaci 0660 i należą do root:dialup (Ubuntu) lub root:uucp (Arch) .Zatem wyróżnionych użytkowników należy dodać do grupy umożliwiającej dostęp do plików urządzeń oraz grupy kontrolującej prawa dostępu do urządzeń dynamicznie łączonych z systememUbuntu&gt; sudo usermod -aG plugdev $USER ; sudo usermod -aG dialup $USERArch&gt; sudo usermod -aG lock $USER ; sudo usermod -aG uucp $USERDodatkowe oprogramowanieW dalszych rozważaniach będzie omawiana konfiguracja VS Code z rozszerzeniem PlatformIO, zatem instalacja tego oprogramowania jest niezbędna.Podczas uruchamiania (debugowania) programów wykonywany jest kod .platformio/packages/toolchain-xtensa-esp32/bin/xtensa-esp32-elf-gdb, który wymaga biblioteki libpython2.7.so, co w normalnym języku oznacza, że konieczna jest instalacja Pythona w wersji 2.W Ubuntu nie jest to problemem, natomiast Arch Linux w oficjalnych repozytoriach nie zawiera już tego oprogramowania. Jego instalacja wymaga otwarcia kanału z oprogramowaniem zarządzanym przez ochotników (tzw. kanał aur) i zbudowanie pakietu ze źródeł.Działania te można bezproblemowo wykonać z poziomu standardowego zarządcy pakietów.Konfiguracja Master-SlaveRolę Master pełni ESP-Prog a urządzenie Slave zrealizowano jako ESP32 DevKitCv4.Część sprzętowaPołączenie złącza PROG` z ESP32            device      connector      pin number      pin name      pin name      device                  ESP-PROG      PROGRAM      1      ESP_EN      EN      ESP32              ESP-PROG      PROGRAM      2      VDD      $3.3V/5V^*$      ESP32              ESP-PROG      PROGRAM      3      ESP_TXD      TX      ESP32              ESP-PROG      PROGRAM      4      GND      GND      ESP32              ESP-PROG      PROGRAM      5      ESP_RXD      RX      ESP32              ESP-PROG      PROGRAM      6      ESP_IO0      $GPIO 0^{**}$      ESP32      $^*$ – zgodnie z napięciem wybranym na zworce przy złączu$^{**}$ – tylko gdy zwarta jest zworka przy złączuPołączenie złącza JTAG z ESP32            device      connector      pin number      pin name      pin name      device                  ESP-PROG      JTAG      1      VDD      $3.3V/5V^1$      ESP32              ESP-PROG      JTAG      2      ESP_TMS      GPIO 14      ESP32              ESP-PROG      JTAG      3      GND      GND      ESP32              ESP-PROG      JTAG      4      ESP_TCK      GPIO 13      ESP32              ESP-PROG      JTAG      6      ESP_TDO      GPIO 15      ESP32              ESP-PROG      JTAG      8      ESP_TDI      GPIO 12      ESP32      $^1$ – zgodnie z napięciem wybranym na zworce przy złączuUwaga!!!Piny urządzenia docelowego wykorzystywane do komunikacji z ESP-Prog nie powinny być kontrolowane przez firmware urządzenia docelowego.Ograniczenie to dotyczy nie tylko nowej wersji, ale również zastępowanego firmware’u.Gdy na urządzeniu docelowym jest zainstalowane nieznane oprogramowanie, to należy je zastąpić wersją spełniającą niniejszy wymóg korzystając ze standardowej metody aktualizacji.Część programowaAdaptacja pliku projektuNiech pierwotna konfiguracja projektu w platform.ini ma postać[env:esp32doit-devkit-v1]board = esp32doit-devkit-v1monitor_speed = 115200platform = espressif32framework = arduinolib_deps =   ayushsharma82/AsyncElegantOTA@^2.2.7  esphome/AsyncTCP-esphome@^2.0.0  esphome/ESPAsyncWebServer-esphome@^3.0.0Wystarczy do niej dopisać następujący fragment...[env:esp32doit-devkit-v1-debug]extends = env:esp32doit-devkit-v1debug_tool = esp-progdebug_init_break = tbreak setup[platformio]default_envs = esp32doit-devkit-v1-debugSekcja [platformio] zapewnia, że nowa konfiguracja stanie się domyślną.W nowej konfiguracji pierwotną wersję uzupełniono tylko dwoma wpisami: debug-tool określa rodzaj urządzenia wykorzystywanego do uruchamiania, natomiast postać debug_init_break ustawia punkt zatrzymania programu (breakpoint) na początku procedury setup.Wgrywanie nowego firmwarePo prostu wystarczy wybrać opcję Upload, tak jak to zwykle się czyni.Zielona dioda na ESP-Prog powinna zacząć mrugać sygnalizując proces wgrywania nowej wersji oprogramowania.Procedura uruchamianiaNa panelu bocznym klikamy ikonę żuczka  (skrót Ctrl-Alt-U) i ze spuszczanej listy wybieramy konfigurację PIO Debug, gdy chcemy zaktualizować firmware przed rozpoczęciem uruchamiania, lub PIO Debug (without uploading), gdy chcemy przejść bezpośrednio do procedury uruchamiania kodu zainstalowanego na urządzeniu docelowym.Uruchamianie można zainicjować naciskając przycisk Play obok nazwy konfiguracji  lub wykorzystując skrót klawiszowy F5.Komunikacja z urządzeniem docelowym jest dość wolna.Po chwili na ekranie powinno pojawić się menu debugera , które obsługujemy normalnie.W oknie kodu źródłowego można ustawiać punkty przerwań wykonania programu, klikając po lewej stronie numeru linii.Konfiguracja Remote DebugCzęść sprzętowaW tej konfiguracji zarówno urządzenie docelowe (DevKitCv4) jak i ESP-Prog połączone są z komputerem PC niezależnie.W konfiguracji wykorzystywane jest tylko złącze JTAG do uruchamiania kodu działającego na urządzeniu docelowym (DevKitCv4).Złącze PROG pozostaje niewykorzystane.Nie ma potrzeby łączenia pinu VDD ponieważ każde urządzenie jest zasilane niezależnie.Podłączenie każdego z urządzeń do komputera PC powoduje pojawienie się nowych plików urządzeń: DevKitC – jednego, ESP-Prog – dwóch.Ich numeracja zależy od kolejności podłączania. Przyjmijmy, że DevKitC został podłączony jako pierwszy.Firmware można do niego zatem wgrać za pomocą interfejsu /dev/ttyUSB0.Podłączenie ESP-Prog powoduje pojawienie się w systemie dwóch kolejnych urządzeń: /dev/ttyUSB1 i /dev/ttyUSB2.Adaptacja pliku projektuNiech pierwotna konfiguracja projektu w platform.ini ma postać[env:esp32doit-devkit-v1]board = esp32doit-devkit-v1monitor_speed = 115200platform = espressif32framework = arduinolib_deps =   ayushsharma82/AsyncElegantOTA@^2.2.7  esphome/AsyncTCP-esphome@^2.0.0  esphome/ESPAsyncWebServer-esphome@^3.0.0Wystarczy do niej dopisać następujący fragment...[env:esp32doit-devkit-v1-debug-standalone]extends = env:esp32doit-devkit-v1upload_port = /dev/ttyUSB0upload_protocol = esptoolmonitor_port = /dev/ttyUSB0debug_tool = esp-progdebug_init_break = tbreak setup[platformio]default_envs = esp32doit-devkit-v1-debug-standaloneJak widać, zmiana w stosunku do poprzedniej metody uruchamiania polega jedynie na jawnej specyfikacji urządzenia wykorzystywanego do aktualizacji firmware’u i obserwacji konsoli szeregowej urządzenia.Procedura uruchamianiaNa panelu bocznym klikamy ikonę żuczka  (skrót Ctrl-Alt-U) i ze spuszczanej listy wybieramy (koniecznie) PIO Debug (without uploading).Następnie uruchamiany sesję debuggera wybierając przycisk Play  lub skrót klawiszowy F5.Reszta procedury przebiega identycznie jak w poprzednim przypadku.PodsumowanieESP-Prog jest dedykowanym programatorem i debuggerem dedykowanym dla platformy ESP32.Oferuje on stabilne i wydajne rozwiązanie do programowania i debugowania układów ESP32.Jego najważniejsze zalety to:      Wsparcie dla JTAG i UART. ESP-Prog umożliwia zarówno debugowanie za pomocą interfejsu JTAG jak i programowanie z wykorzystaniem interfejsu UART.        Debugowanie w czasie rzeczywistym: Dzięki ESP-Prog można wykonywać debugowanie w czasie rzeczywistym, co ułatwia identyfikację i rozwiązywanie problemów w kodzie podczas jego wykonywania na platformie ESP32.        Łatwa integracja z PlatformIO: ESP-Prog jest dobrze zintegrowany z PlatformIO - popularnym narzędziem do rozwoju oprogramowania dla układów mikrokontrolerów. Umożliwia to wygodne i efektywne programowanie i debugowanie projektów ESP32 w środowisku PlatformIO, w szczególności w Visual Studio Code.        Wsparcie dla różnych płytek deweloperskich: ESP-Prog jest kompatybilny z różnymi płytkami deweloperskimi ESP32, co oznacza, że ​​można go używać z wieloma różnymi układami ESP32 bez konieczności zakupu wielu różnych programatorów.  Bibliografia[1] https://docs.espressif.com/projects/espressif-esp-iot-solution/en/latest/hw-reference/ESP-Prog_guide.html"
  },
  
  {
    "title": "Jak kompilować i debugować aplikacje w C/C++ na komputery jednopłytkowe korzystając z VS Code",
    "url": "/posts/C-Cpp-development-for-SBC-in-Code/",
    "categories": "",
    "tags": "C/C++, SBC, Docker, DevContainers",
    "date": "2023-08-12 15:13:20 +0200",
    





    
    "snippet": "Komputery jednopłytkowe (ang. SBC — Single Board Computer) to uniwersalne urządzenia mikroprocesorowe pracujące pod kontrolą systemu operacyjnego.Zazwyczaj systemem tym jest Linux.Architektury komp...",
    "content": "Komputery jednopłytkowe (ang. SBC — Single Board Computer) to uniwersalne urządzenia mikroprocesorowe pracujące pod kontrolą systemu operacyjnego.Zazwyczaj systemem tym jest Linux.Architektury komputerów jednopłytkowych mogą istotnie się różnić od architektur stosowanych dla komputerów osobistych.W rezultacie przygotowanie aplikacji w postaci binarnej na urządzenie docelowe (target) na komputerze osobistym (host) wymaga wielu, często dość skomplikowanych, zabiegów.Uwaga niniejszego opracowania skupiona jest na realizacji różnych scenariuszy pracy z wykorzystaniem edytora VS Code i eliminujących konieczność instalacji i konfiguracji środowiska graficznego na SBC.Producenci urządzeń klasy SBC nieustannie przekonują potencjalnych nabywców, że urządzenia te mogą funkcjonować jako ubogie wersje komputerów osobistych, jednak nie znam nikogo, kto używałby ich w ten sposób.Tak naprawdę siłą komputerów tego typu jest dostępność niskopoziomowych interfejsów takich, jak linie GPIO czy magistrale I2C, SPI przy jednoczesnej dostępności wielu serwisów sieciowych.Jądro systemu operacyjnego zainstalowanego na takim urządzeniu zapewnia abstrakcyjny interfejs dostępu sprzętu, dzięki czemu aplikacje wyglądają w zasadzie tak samo, niezależnie od platformy sprzętowej wykorzystanej do realizacji urządzenia SBC.Idealną sytuacją byłoby, gdyby aplikacje dla komputera jednopłytkowego można było tworzyć, budować i uruchamiać bezpośrednio na nim. Komfortowa praca wymaga jednak uruchomienia konsoli graficznej (instalacji oprogramowania oraz doposażenia w dodatkowy sprzęt w postaci myszy, klawiatury i monitora), zapewnienia odpowiedniej przestrzeni dyskowej i wystarczającego rozmiaru pamięci RAM.Scenariusz taki jest możliwy, gdy SBC ma zasoby porównywalne z komputerami PC.W zdecydowanej większości przypadków tak nie jest.We wszystkich opisanych dalej scenariuszach jedynym interfejsem programisty będzieVisual Studio Code – doceniony przez programistów i wysoce konfigurowalny edytor.Mechanizm rozszerzeń w edytorze umożliwia jego uzupełnienie o funkcje budowania i uruchamiania aplikacji co de facto przekształca go w zintegrowane środowisko pracy. VS Code jest dostępny nieodpłatnie na wszystkie popularne systemy operacyjne. Pracę z projektami C/C++ znacznie ułatwia *C/C++ Extension Pack*. Dalej przyjęto, że rozszerzenie to jest zainstalowane.Rozważane są scenariusze pracy w których kod aplikacji jest budowany na urządzeniu docelowym lub komputerze PC.1. Kompilacja natywnaOpisane w tym punkcie scenariusze wymagają instalacji w systemie target narzędzi umożliwiających budowanie aplikacji, np.apt install -y build-essentials makeapt install -y libgpiod-devVS Code jest wykorzystywane jedynie do zapewnienia programiście wygodnego interfejsu graficznego.1.1 Praca zdalna z wykorzystaniem Code ServerInstalacja w Visual Studio Code rozszerzenia Remote SSH umożliwia pracę zdalną na dowolnym koncie SSH, tak jak gdyby był to komputer lokalny. W procesie automatycznej konfiguracji zdalnego konta na systemie target jest instalowany i uruchamiany Code Server.Otwarcie zdalnej sesji przebiega następująco:      po uruchomieniu Visual Studio Code wystarczy wybrać zielony przycisk “” w lewym dolnym rogu ekranu        z palety komend wybrać “Connect to Host”,        w polu adresu wpisać root@opi.usb (“root” można zamienić na dowolne inne konto, “opi.usb” jest nazwą sieciową systemu target i może być zamieniona na stosowny numer IP),  Rozszerzenie Remote SSH automatycznie zainstaluje na zdalnym koncie oprogramowanie Code Server (w katalogu ‘.vscode’ na zdalnym koncie) umożliwiające egzekucję i odbieranie wyników komend wydawanych w tunelu SSH.Praca w takiej konfiguracji jest bardzo wygodna i w zasadzie niczym nie różni się od pracy lokalnej. Jedyna różnica polega na tym, że źródła aplikacji i narzędzia ich kompilacji muszą być obecne na systemie target. Na systemie host nie trzeba instalować nić oprócz Visual Studio Code.Niestety, przedstawione rozwiązanie ma dwie (poważne) wady:      code-server wspiera tylko architektury 64-bitowe: amd64 i arm64, co na wyklucza zastosowanie tego podejścia na wielu dostępnych na rynku SBC,        system target powinien być wyposażony w 1GB RAM i dwurdzeniowy CPU.  1.2 Praca zdalna w tunelu SSHPoprzednia metoda nie jest uniwersalna ze względu na wymagania stawiane przez Code Server.Element ten można wyeliminować z poprzedniego schematu.Tym razem pliki źródłowe są edytowane na systemie host i przed kompilacją kopiowane na system target, gdzie są kompilowane za pomocą natywnych narzędzi.W toku dalszego wywodu zostanie przyjęto następującą strukturę podkatalogów w katalogu projektu.vscode/ -&gt; katalog z plikami konfiguracyjnymi IDEobj/ -&gt; katalog pomocniczy dla makesrc/ -&gt; pliki źródłowe projektusrc/include/src/main.cMakefile Powyższy projekt można zbudować natywnie, korzystając z następującego ‘Makefile’# Compiler settings - Can be customized.CC = gccCXX = g++CPPFLAGS =CFLAGS = -std=c11 -g -Wall -fdiagnostics-color=alwaysCXXFLAGS = -std=c++11 -g -Wall -fdiagnostics-color=alwaysLDFLAGS = -lpthread -lgpiod# Makefile settings - Can be customized.APPNAME = mainEXT = .cSRCDIR = srcOBJDIR = objREMOTE = root@opi.usbREMOTEPWD = /root/RemotePowerButtonSRC = $(wildcard $(SRCDIR)/*$(EXT))OBJ = $(SRC:$(SRCDIR)/%$(EXT)=$(OBJDIR)/%.o)DEP = $(OBJ:$(OBJDIR)/%.o=%.d)RM = rmall: $(APPNAME)# Copy sources to targetcopysrc:  scp -p -r ./src/ ./obj/ ./Makefile $(REMOTE):$(REMOTEPWD)# Builds the app$(APPNAME): $(OBJ)  $(CC) $(CFLAGS) -o $@ $^ $(LDFLAGS)# Creates the dependecy rules%.d: $(SRCDIR)/%$(EXT)  @$(CPP) $(CFLAGS) $(CPPFLAGS) $&lt; -MM -MT $(@:%.d=$(OBJDIR)/%.o) &gt;$@# Includes all .h files-include $(DEP)# Building rule for .o files and its .c/.cpp in combination with all .h$(OBJDIR)/%.o: $(SRCDIR)/%$(EXT)  $(CC) $(CFLAGS) $(CPPFLAGS) -o $@ -c $&lt;# Cleans complete project.PHONY: cleanclean:  -$(RM) $(OBJ) $(DEP) $(APPNAME)# Cleans only all files with the extension .d.PHONY: cleandepcleandep:  -$(RM) $(DEP)W powyższym pliku cel ‘copysrc’ odpowiada za skopiowanie na system target struktury katalogów i plików niezbędnych do zbudowania aplikacji.Plikiem konfiguracyjnym mówiącym Visual Studio Code jak należy dany projekt budować, jest plik ‘.vscode/tasks.json’.Każdy projekt może mieć kilka zadań, do których odwołujemy się przez nazwę nadaną w polu ‘label’. Zadania budowania konfiguruje się w menu ‘Terminal’.Konfiguracja zadania, które kopiuje pliki źródłowe na system target, a następnie zdalnie wykonuje na nim polecenie ‘make’ wygląda następująco (plik ‘.vscode/tasks.json’):{  \"version\": \"2.0.0\",  \"tasks\": [    {      \"label\": \"Native Build on Target\",      \"type\": \"shell\",      \"command\": \"make copysrc ; ssh root@opi.usb '(cd /root/RemotePowerButton; make)'\",      \"group\": {          \"kind\": \"build\",          \"isDefault\": true      },      \"options\": {        \"cwd\": \"${workspaceFolder}\"      },      \"problemMatcher\": [          \"$gcc\"      ],      \"detail\": \"This task copies project sources to target and then it builds them natively there.\"    }  ]}Przyjęto, że zdalnym katalogiem projektu jest ‘/root/RemotePowerButton’. Procedurę budowania aktywuje się skrótem klawiszowym ‘Ctrl+Shift+B’.Edytor Visual Studio Code jest wyposażony w mechanizm IntelliSense bardzo ułatwiający pisanie kodu źródłowego poprzez zastosowanie zaawansowanego mechanizmu podpowiedzi nt. zdefiniowanych zmiennych, dostępnych funkcji, akceptowanych przez nie argumentów itp.IntelliSense czerpie swoją wiedzę z analizy treści plików nagłówkowych.W przedstawionej tutaj konfiguracji problem polega na tym, że IntelliSense korzysta z plików nagłówkowych w systemie host, które mogą być zupełnie odmienne od odpowiednich plików w systemie target.Aby tę niefortunny stan rzeczy naprawić, należy pliki nagłówkowe z systemu target udostępnić IntelliSense.Procedura jest dwuetapowa:      pliki nagłówkowe z systemu target, muszą być widoczne w systemie host,        IntelliSense musi być poinformowane, gdzie się te pliki znajdują.  Punkt 1. można zrealizować na dwa sposoby:      metodą “brutalnej siły” polegającej na skopiowaniu rzeczonych plików nagłówkowych na system host (przeniesienie atrybutu właściciela pliku nie jest konieczne),    # w katalogu projektu na systemie hostmkdir -p rootfs/usr/includescp -r root@opi.usb:/usr/include rootfs/usr/include/            metodą “elegancką” polegającą na udostępnieniu w trybie tylko do odczytu odpowiedniego fragmentu systemu plików systemu target z wykorzystaniem protokołu NFS.  Metoda “brutalnej siły” ma tę wadę, że przynajmniej co do zasady, powinna być powtórzona po każdorazowej aktualizacji oprogramowania na systemie target.Metodę elegancką opisano w punkcie “Kruczki i sztuczki”.Następnie, korzystając z pliku ‘.vscode/c_cpp_properties.json’ należy poinformować IntelliSense, które pliki powinny być analizowane{    \"configurations\": [        {            \"name\": \"Target Rootfs\",            \"includePath\": [                \"${workspaceFolder}/src/**\",                \"${workspaceFolder}/rootfs/**\"            ],            \"defines\": [ // symbols resolved by the preprocessor that are unknown to IntelliSense                \"NULL=0\" // I suspect that \"#     define NULL 0\" in types.h is accepted by cpp, but IGNORED by IntelliSense             ],            \"compilerPath\": \"\",            \"cStandard\": \"c11\",            \"cppStandard\": \"c++11\",            \"intelliSenseMode\": \"linux-gcc-arm64\"        }    ],    \"version\": 4}Zagadnienie udostępnienia właściwych plików nagłówkowych będzie się przewijało we wszystkich opisywanych dalej konfiguracjach. W wersji korzystającej z plików udostępnionych za pomocą NFS katalog ‘rootfs’ może być po prostu linkiem symbolicznym do katalogu, w którym widoczne są pliki urządzenia target.2. Kompilacja skrośnaProces budowania aplikacji złożony jest dwóch zasadniczych etapów:      kompilacji, czyli przekształcenia kodu źródłowego na kod binarny dla docelowej architektury,        łączenia (ang. liniking), czyli zebrania wielu fragmentów kodu binarnego w jedną aplikację.  Kompilacji podlega kod źródłowy stworzony przez twórcę oprogramowania wraz z kodem zawartym w plikach nagłówkowych bibliotek.Łączeniu podlega kod binarny wyprodukowany w procesie kompilacji z kodem binarnym bibliotek. Kompilator czerpie z plików nagłówkowych informację o kodzie, który będzie dostępny na etapie łączenia, zatem oba te elementy muszą pozostawać w pełnym synchronizmie.Sam proces łączenia ma dwie odmiany.W łączeniu statycznym wymuszanym na linkerze opcją -static kod binarny aplikacji oraz wspomagający go kod z bibliotek są ‘sklejane’ w jeden plik.Tak zbudowana aplikacja jest samowystarczalna, jednak jej kod wynikowy może być bardzo duży (np. użycie funkcji printf implikuje dołączenie znacznego fragmentu standardowej biblioteki C).Bez opcji -static linker pracuje w trybie łączenia dynamicznego, w którym kod binarny aplikacji jest uzupełniany informacją o nazwie i wersji biblioteki, o którą powinien być uzupełniony w momencie uruchomienia. Dzięki takiemu podejściu kod wynikowy aplikacji jest stosunkowo mały, a biblioteki wykorzystywane przez wiele aplikacji są ładowane do pamięci tylko raz. Niestety, w momencie uruchomienia aplikacja nie jest samodzielna jak w przypadku łączenia statycznego, gdyż system, w którym jest uruchamiana, musi być uzupełniony o biblioteki współdzielone niezbędne do działania aplikacji (z dokładnością do wersji biblioteki, aby zapewnić zgodność interfejsu biblioteki zakładanego podczas kompilacji).Ostatecznie budowanie skrośne wymaga spełnienia następujących warunków:      kompilator musi wytwarzać kod binarny zgodny z architekturą urządzenia target,        przetwarzane przez kompilator pliki nagłówkowe muszą być zgodne z kodem binarnym łączonym przez linker,        na etapie uruchamiania, dla programów łączonych dynamicznie, w systemie target muszą być zainstalowane dokładnie te same biblioteki, które były przyjęte na etapie łączenia.Mówiąc krótko, architektura kodu, deklaracje zawarte w kodach nagłówkowych i biblioteki podczas łączenia i uruchamiania aplikacji muszą do siebie pasować.  Podstawowym problemem skrośnego tworzenia oprogramowania jest konstrukcja środowiska gwarantującego spełnienie warunków 1-3.Ich poprawne spełnienie wymaga istotnej ingerencji w oprogramowanie zainstalowane na systemie host.Zestaw narzędzi umożliwiających przygotowanie kodu binarnego na architekturę inną niż architektura systemu na którym wykonywania jest kompilacja nazywa się toolchain‘em.Nazwa ta podkreśla fakt, że skrośne budowanie aplikacji wymaga zharmonizowanego użycia wielu narzędzi.Skrośne budowanie aplikacji jest żmudne i podatne na błędy2.1 Instalacja kompilatora skrośnego w systemie hostBudowanie skrośne jest stosunkowo proste, gdy dla systemu host istnieje gotowy pakiet zawierający zestaw narzędzi do skrośnego budowania aplikacji (tzw. toolchain) oraz podstawowe biblioteki dla architektury docelowejapt list \"crossbuild*\"Jego instalacja umożliwia bezproblemową kompilację prostych aplikacji.Problem koegzystencji został rozwiązany poprzez zastosowanie konwencji nazewniczej polegającej na poprzedzeniu każdego programu wchodzącego w skład toolchainu prefiksem opisującym platformę docelową w formacie (łącznik na końcu prefiksu jest jego integralną częścią)&lt;arch&gt;-&lt;os&gt;-&lt;lib&gt;-&lt;arch&gt;-&lt;vendor&gt;-&lt;os&gt;-&lt;lib&gt;-Na przykład typowymi prefiksami dla architektury ARM64 są aarch64-linux-gnu- lub aarch64-unknown-linux-gnu-Łączenie statyczneSzansa, że wersje bibliotek zainstalowanych w ‘crossbuild’ pokrywają się z bibliotekami w środowisku uruchomiania, jest niewielka, zatem konieczne jest uwolnienie się od warunku 3, poprzez wymuszenie łączenia statycznego np.PREFIX=aarch64-linux-gnu- ; ${PREFIX}gcc -c -g -Wall -o main.o main.c ; ${PREFIX}gcc -static main.oKompilator i linker skrośny ‘wiedzą’, gdzie w systemie host zainstalowano pliki stosowne dla architektury docelowej, co znacznie upraszcza składnię komend niezbędnych do skutecznego zbudowania aplikacji.Aplikacja zbudowana jak wyżej może być uruchomiona na dowolnym systemie zgodnym z architekturą zdefiniowaną w zmiennej PREFIX.Jednak za prostotę płacimy cenę: po pierwsze, aplikacja jest stosunkowo duża i po drugie, uzupełnienie zależności o bibliotekę, której brak w pakiecie ‘crossbuild*’ wymaga ręcznej kompilacji skrośnej biblioteki i ujęcia jej explicite w wywołaniach kompilatora i linkera.Łączenie dynamiczneBudowanie skrośne wykorzystujące łączenie dynamiczne jest bardziej złożone, gdyż na systemie host muszą znajdować te same biblioteki dynamiczne/współdzielone co na systemie target.Spełnienie punktu 3 implikuje również instalację plików nagłówkowych skojarzonych z tymi bibliotekami.Katalog zawierający te elementy jest nazywany sysroot. Zarówno kompilator skrośny, jak i linker skrośny muszą być poinformowane o jego położeniu. Zawartość sysroot ekstrahuje się z głównego systemu plików systemu target.Wymóg utrzymania synchronizmu wymusza aktualizację jego kopii na systemie host po zmianie firmware na urządzeniu target.PREFIX=aarch64-linux-gnu- ; SYS=rootfs ;${PREFIX}gcc --sysroot ${SYS} -c -g -Wall -o main.o main.c ; ${PREFIX}gcc --sysroot ${SYS} main.oWartość zmiennej PREFIX jest używana do rozmieszczania plików w drzewie katalogów na etapie przygotowywania rootfs.Jednocześnie jest ona wykorzystywana przez kompilator skrośny do poszukiwania plików.Zatem łączenie dynamiczne aby prefiks kompilatora był taki sam jak dla rootfs.Spełnienie tego warunku jest konieczne do bezproblemowej kompilacji i łączenia w trybie dynamicznymInną, bardziej elegancką metodą zapewnienia widoczności plików z urządzenia target jest ich udostępnienie z wykorzystaniem protokołu NFS.Poniżej przedstawiono definicje zadań kompilacji statycznej i dynamicznej w Visual Studio Code.Dla kompilacji dynamicznej przyjęto założenie, że system plików urządzenia target jest widoczny w katalogu ‘rootfs/’.{  \"version\": \"2.0.0\",  \"tasks\": [    {      \"label\": \"CrossBuild with static linkage\",      \"type\": \"shell\",      \"command\": \"make PREFIX=aarch64-linux-gnu- STATIC=-static\",      \"group\": {        //\"isDefault\": true,        \"kind\": \"build\"      },      \"options\": {        \"cwd\": \"${workspaceFolder}\"      },      \"problemMatcher\": [          \"$gcc\"      ],      \"detail\": \"This task creates static application produced with cross compiler installed on host.\"    },    {      \"label\": \"CrossBuild with dynamic linkage\",      \"type\": \"shell\",      \"command\": \"make PREFIX=aarch64-linux-gnu- SYSROOT=rootfs/\",      \"group\": {        //\"isDefault\": true,        \"kind\": \"build\"      },      \"options\": {        \"cwd\": \"${workspaceFolder}\"      },      \"problemMatcher\": [          \"$gcc\"      ],      \"detail\": \"This task creates dynamically linked application produced with cross compiler installed on host. Target's rootfs is visible in rootfs/ folder.\"    }  ]}2.2 Konteneryzacja środowiska kompilacji skrośnejInstalowanie w systemie host kilku środowisk skrośnych prowadzi do dość sporego zamieszania w organizacji plików, zwłaszcza jeżeli narzędzia te pochodzą z równych źródeł.Atrakcyjną alternatywą jest zamknięcie tych środowisk w kontenerach Docker‘a.Zaletą jest o wiele łatwiejsze zarządzanie i całkowity brak interferencji pomiędzy tak zorganizowanymi środowiskami.W ramach projektu Dockcross zamknięto w kontenerach narzędzia kompilacji na wiele platform docelowych.Ich zawartość obejmuje narzędzia do budowania aplikacji oraz standardową bibliotekę C (zrealizowaną jako GNU C, musl lub uClib).Korzystanie z kontenerów jest wyjątkowo proste: instalacja sprowadza się do jednej komendy, a budowanie aplikacji wymagaja kosmetycznego retuszu pliku Makefile.Dostępne typy architektur można sprawdzić w repozytorium GitHub projektu https://github.com/dockcross/dockcross lub na https://hub.docker.com/.Instalację środowiska realizuje komendadocker run --rm dockcross/arch-name &gt; ./dockcrosschmod +x ./dockcrossW jej wyniku na system host zostanie pobrany odpowiedni kontener, a w katalogu projektu utworzony skrypt dockcross umożliwiający korzystanie z jego zawartości.Jeżeli kontener ma być używany również w innych projektach to skrypt należy przenieść do katalogu znajdującego się na ścieżce dostępu i zmienić jego nazwę na taką, która informuje o nazwie architektury. Parametry linii komend tego skryptu traktowane są jak linia poleceń, którą należy przekazać do kontenera.Jednocześnie bieżący katalog jest mapowany do wnętrza kontenera, co powoduje, że pliki projektu są dostępne dla kompilatora w katalogu roboczym kontenera.Na przykład, aby sprawdzić jak nazywa się kompilator umieszczony w kontenerze wystarczy wydać komendę./dockcross bash -c 'echo $CC'Powyższa komenda pozwala na ustalenie wartości zmiennej PREFIX używanej we wcześniejszych przykładach.Na przykład dla kontenera dockcross/linux-arm64 przyjmie ona wartość aarch64-unknown-linux-gnu-.W rezultacie komenda realizująca kompilację skrośną wymaga prostego uzupełnienia o wywołanie skryptu./dockcross bash -c 'PREFIX=aarch64-unknown-linux-gnu- ; ${PREFIX}gcc -c -g -Wall -o main.o main.c ; ${PREFIX}gcc -static main.o -o myapp'{  \"version\": \"2.0.0\",  \"tasks\": [    {      \"label\": \"Containerized CrossBuild with static linkage\",      \"type\": \"shell\",      \"command\": \"./dockcross bash -c 'make PREFIX=aarch64-unknown-linux-gnu- STATIC=-static'\",      \"group\": {        //\"isDefault\": true,        \"kind\": \"build\"      },      \"options\": {        \"cwd\": \"${workspaceFolder}\"      },      \"problemMatcher\": [          \"$gcc\"      ],      \"detail\": \"This task creates static application produced with cross compiler installed dockcross container (https://github.com/dockcross/dockcross).\"    }  ]}Niestety, z dużym prawdopodobieństwem kompilator zawarty w kontenerze będzie niekompatybilny z kompilatorem użytym do wytworzenia rootfs. W efekcie łączenie w trybie dynamicznym nie będzie możliwe.3. Debugowanie skrośneNatywne debugowanie kodu z wykorzystaniem GUI pracującego na systemie target jest często awykonalne, głównie ze względu na ograniczony interfejs użytkownika i niezbyt duże zasoby urządzenia.Z kolei zdalna praca w konsoli tekstowej z debuggerem gdb jest doznaniem ekstremalnym.Rozwiązaniem problemu jest podzielenie zadania uruchamiania na dwa oddzielne procesy. Proces gdbserver pracuje na systemie target i odpowiada za krokowe wykonywanie uruchamianej aplikacji.Z kolei interfejs użytkownika uruchomiony na systemie host komunikuje się z serwerem poprzez sieć lub łącze szeregowe (w dalszej części pojawią się konfiguracje dla łącza sieciowego).Programem uruchomionym na systemie host jest gdb-multiarch (jest to wersja gdb, która “rozumie” różne architektury). Oba komponenty komunikują się za pomocą protokołu TCP/IP.W efekcie struktura komunikacji pomiędzy narzędziami jest następująca: interfejs GUI uruchomiony w systemie host komunikuje się lokalnie z gdb-multiarch, który z kolei poprzez sieć komunikuje się z gdbserver uruchomionym na systemie target.GUI odpowiedzialne za przeprowadzenie sesji uruchamiania musi poinformować gdb-multiarch o architekturze uruchamianego kodu i adresie serwera oczekującego na połączenie.W Visual Studio Code za konfigurację procesu uruchamiania odpowiedzialny jest plik ‘.vscode/launch.json’.Dla rozważanego projektu przyjmie on postać{  \"version\": \"0.2.0\",  \"configurations\": [    {      \"name\": \"GDB-REMOTE\",      \"type\": \"cppdbg\",      \"request\": \"launch\",      \"program\": \"${workspaceFolder}/main\",      \"miDebuggerServerAddress\": \"opi.usb:1234\",      \"miDebuggerPath\": \"/usr/bin/gdb-multiarch\",      \"targetArchitecture\": \"arm64\",      \"args\": [],      \"stopAtEntry\": true,      \"cwd\": \"${workspaceFolder}\",      \"environment\": [],      \"externalConsole\": false,      \"MIMode\": \"gdb\",      \"setupCommands\": [        {          \"description\": \"sets target architecture\",          \"text\": \"-ex 'set architecture aarch64'\",          \"ignoreFailures\": true        },        {          \"description\": \"Enable pretty-printing for gdb\",          \"text\": \"-enable-pretty-printing\",          \"ignoreFailures\": true        }      ]    }  ]}Sesję uruchamiania aktywuje się skrótem “F5” lub wybierając ikonę “żuczka”  na pasku bocznym.Powyższe zadanie realizuje tylko komunikację lokalną z gdb-multiarch, tak więc każdorazowo przed rozpoczęciem sesji uruchamiania należy w terminalu Visual Studio Code wydać komendęscp ./main root@opi.usb: &amp;&amp; ssh -t root@opi.usb \"gdbserver --once localhost:1234 ./main\"Zadanie można sobie znacznie ułatwić, dopisując odpowiednie cele do ‘Makefile’debug: $(APPNAME)  scp $(APPNAME) $(REMOTE): &amp;&amp; ssh -t $(REMOTE) \"gdbserver --once localhost:1234 ./$(APPNAME)\"run: $(APPNAME)  scp $(APPNAME) $(REMOTE): &amp;&amp; ssh -t $(REMOTE) \"./$(APPNAME)\"PodsumowanieKompilacja skrośna własnego kodu nastręcza wielu problemów.Jeszcze więcej problemów pojawia się podczas kompilacji cudzych aplikacji.Profesjonalnie napisane aplikacje są wyposażone w mechanizm budowy dostosowujący je do środowiska kompilacji.Zazwyczaj budowanie aplikacji poprzedzonej jest uruchomieniem skryptu ./configurewygenerowanym przez środowisko automake.Zadaniem skryptu jest wykrycie dostępności pewnych składników systemie, ustawienie odpowiednich flag kompilacji i przygotowanie pliku Makefile dla programu make.Schemat ten działa poprawnie gdy system na którym ma być wykonywania aplikacja jest identycznie skonfigurowany (w sensie dostępności wykrywanych składników) z systemem na którym wykonywana jest aplikacja.W przypadku kompilacji skrośnej założenie to nie jest spełnione.Skrypt ./configure po prostu odpytuje niewłaściwy system.W efekcie ustawione opcje kompilacji są niepoprawne, co skutkuje błędami kompilacji, lub co gorsza, wygenerowaniem niewłaściwie działającego kodu.Ręczny dobór odpowiednich przełączników i adaptacja obcego kodu źródłowego jest zazwyczaj doznaniem ekstremalnym.W zasadzie wszystkie opisane problemy można rozwiązać stosując kompilację w trybie emulowanym.Wady i zaletyBudowanie natywne            zalety      wady                  możliwość tworzenie kodu łączonego dynamicznie      konieczność instalacji narzędzi deweloperskich na urządzeniu *target*                     tworzenie kodu wymaga bezpośredniego dostepu do urządzenia docelowego      Budowanie skrośne            zalety      wady                  kompilacja na urządzeniu host      kod łączony dynamicznie może być przygotowany tylko w specyficznych sytuacjach              możliwość hermetyzacji środowiska w kontenerze             Przydatne pliki konfiguracyjneMakefile na wszystkie okazje# Compiler settings - Can be customized.PREFIX=STATIC=CC = $(PREFIX)gccCXX =$(PREFIX)g++CPPFLAGS =CFLAGS = -std=c11 -g -Wall -fdiagnostics-color=alwaysCXXFLAGS = -std=c++11 -g -Wall -fdiagnostics-color=always# LDFLAGS = $(STATIC) -lpthread -lgpiod LDFLAGS = $(STATIC) ifdef SYSROOT    CFLAGS += --sysroot=$(SYSROOT)    CXXFLAGS += --sysroot=$(SYSROOT)    LDLAGS += --sysroot=$(SYSROOT)endif# Makefile settings - Can be customized.APPNAME = mainEXT = .cSRCDIR = srcOBJDIR = objREMOTE = root@opi.usbREMOTEPWD = /root/RemotePowerButtonSRC = $(wildcard $(SRCDIR)/*$(EXT))OBJ = $(SRC:$(SRCDIR)/%$(EXT)=$(OBJDIR)/%.o)DEP = $(OBJ:$(OBJDIR)/%.o=%.d)RM = rm -fall: $(APPNAME)# Copy sources to target.PHONY: copysrccopysrc:  scp -p -r ./src/ ./obj/ ./Makefile $(REMOTE):$(REMOTEPWD).PHONY: debugdebug: $(APPNAME)  scp $(APPNAME) $(REMOTE): &amp;&amp; ssh -t $(REMOTE) \"gdbserver --once localhost:1234 ./$(APPNAME)\".PHONY: runrun: $(APPNAME)  scp $(APPNAME) $(REMOTE): &amp;&amp; ssh -t $(REMOTE) \"./$(APPNAME)\"# Builds the app$(APPNAME): $(OBJ)  $(CC) $(CFLAGS) -o $@ $^ $(LDFLAGS)# Creates the dependecy rules%.d: $(SRCDIR)/%$(EXT)  @$(CPP) $(CFLAGS) $(CPPFLAGS) $&lt; -MM -MT $(@:%.d=$(OBJDIR)/%.o) &gt;$@# Includes all .h files-include $(DEP)# Building rule for .o files and its .c/.cpp in combination with all .h$(OBJDIR)/%.o: $(SRCDIR)/%$(EXT)  $(CC) $(CFLAGS) $(CPPFLAGS) -o $@ -c $&lt;# Cleans complete project.PHONY: cleanclean:  $(RM) $(OBJ) $(DEP) $(APPNAME)# Cleans only all files with the extension .d.PHONY: cleandepcleandep:  $(RM) $(DEP)Wszystkie definicje zadań `.vscode/tasks.json’{  \"version\": \"2.0.0\",  \"tasks\": [    {      \"label\": \"CrossBuild with static linkage\",      \"type\": \"shell\",      \"command\": \"make PREFIX=aarch64-linux-gnu- STATIC=-static\",      \"group\": {        //\"isDefault\": true,        \"kind\": \"build\"      },      \"options\": {        \"cwd\": \"${workspaceFolder}\"      },      \"problemMatcher\": [          \"$gcc\"      ],      \"detail\": \"This task creates static application produced with cross compiler installed on host.\"    },    {      \"label\": \"CrossBuild with dynamic linkage\",      \"type\": \"shell\",      \"command\": \"make PREFIX=aarch64-linux-gnu- SYSROOT=/mnt/sysroot\",      \"group\": {        //\"isDefault\": true,        \"kind\": \"build\"      },      \"options\": {        \"cwd\": \"${workspaceFolder}\"      },      \"problemMatcher\": [          \"$gcc\"      ],      \"detail\": \"This task creates dynamically linked application produced with cross compiler installed on host. Targets rootfs is visible in /mnt/sysroot.\"    },    {      \"label\": \"Build Natively on Target\",      \"type\": \"shell\",      \"command\": \"make copysrc ; ssh root@opi.usb '(cd /root/RemotePowerButton; make)'\",      \"group\": {        //\"isDefault\": true,        \"kind\": \"build\"      },      \"options\": {        \"cwd\": \"${workspaceFolder}\"      },      \"problemMatcher\": [          \"$gcc\"      ],      \"detail\": \"This task copies project sources to target and then it builds them natively there.\"    }  ]}Konfiguracja IntelliSense w ‘.vscode/c_cpp_properties.json’{    \"configurations\": [        {            \"name\": \"NativeOverSSH\",            \"includePath\": [                \"${workspaceFolder}/src/**\",                \"${workspaceFolder}/rootfs/**\"            ],            \"defines\": [ // symbols resolved by the preprocessor that are unknown to IntelliSense                \"NULL=0\" // I suspect that \"#     define NULL 0\" in types.h is accepted by cpp, but IGNORED by IntelliSense             ],            \"compilerPath\": \"\",            \"cStandard\": \"c11\",            \"cppStandard\": \"c++11\",            \"intelliSenseMode\": \"linux-gcc-arm64\"        }    ],    \"version\": 4}Konfiguracja sesji uruchamiania w ‘.vscode/launch.json’{  \"version\": \"0.2.0\",  \"configurations\": [    {      \"name\": \"GDB-REMOTE\",      \"type\": \"cppdbg\",      \"request\": \"launch\",      \"program\": \"${workspaceFolder}/main\",      \"miDebuggerServerAddress\": \"opi.usb:1234\",      \"miDebuggerPath\": \"/usr/bin/gdb-multiarch\",      \"targetArchitecture\": \"arm64\",      \"args\": [],      \"stopAtEntry\": true,      \"cwd\": \"${workspaceFolder}\",      \"environment\": [],      \"externalConsole\": false,      \"MIMode\": \"gdb\",      \"setupCommands\": [        {          \"description\": \"sets target architecture\",          \"text\": \"-ex 'set architecture aarch64'\",          \"ignoreFailures\": true        },        {          \"description\": \"Enable pretty-printing for gdb\",          \"text\": \"-enable-pretty-printing\",          \"ignoreFailures\": true        }      ]    }  ]}4. Kruczki i sztuczki4.1 Zdalny dostęp do konta administratora bez podawania hasła      Zdalny dostęp do konta administratora    W pliku /etc/ssh/sshd_config’ (target) należy ustawić opcję     PermitRootLogin   yes        Logowanie bez konieczności podawania hasła                  Serwer ssh musi zezwalać na uwierzytelnienie za pomocą kluczy publicznych.W pliku /etc/ssh/sshd_config’ (target) należy ustawić opcje        PubkeyAuthentication   yesAuthorizedKeysFile    .ssh/authorized_keys    .ssh/authorized_keys2                    Użytkownik systemu host musi mieć wygenerowane osobiste klucze ssh. Generacja komendą        ssh-keygen        Opcją ‘-t’ można wymusić typ klucza, a opcją ‘-b’ jego długość. Wygenerowane klucze, prywatny i publiczny, umieszczone są w podkatalogu ‘.ssh’ katalogu domowego (publiczny ma rozszerzenie ‘pub’).                    Klucz publiczny należy umieścić na systemie target w pliku ‘.ssh/authorized_keys’ nakoncie docelowym. Wygodne kopiowanie zapewnia komenda (poniżej użyto konta root)        ssh-copy-id root@opi.usb                    4.2 Udostępnianie głównego systemu plików poprzez NFSSystem target      Instalacja serwera NFS.     apt install -y nfs-kernel-server            Udostępnienie katalogu ‘/usr’ w trybie tylko do odczytu    Zatrzymanie serwera     systemctl stop nfs-kernel-server        Aktualizacja ‘/etc/exports’     /usr *(ro,sync,no_subtree_check)        Uruchomienie serwera     exportsfs -ra systemctl start nfs-kernel-server      System host      Utworzenie punktu montowania     mkdir -p /mnt/sysroot/usr            Montowanie zdalnego folderu na żądanie. W ‘/etc/fstab’     opi.usb:/usr /mnt/sysroot/usr  nfs noauto,nofail,noatime,nolock  0 0        Montowanie komendą     sudo mount /mnt/sysroot/usr        Kompilator należy poinformować, że katalogiem ‘sysroot’ jest ‘/mnt/sysroot’.  P.S. Chętnie się dowiem jak prosto udostępnić “/” w którym są linki symboliczne np. bin-&gt;/usr/bin."
  },
  
  {
    "title": "Jak założyć i utrzymywać statyczny serwis WWW wykorzystując Docker'a, Code i Hugo",
    "url": "/posts/static-site-in-hugo/",
    "categories": "Programowanie",
    "tags": "Code, DevContainer, Hugo, Github Actions",
    "date": "2023-08-05 12:06:43 +0200",
    





    
    "snippet": "W poradniku pokazano jak wykorzystać konteneryzację i wsparcie dla niej w Visual Studio Code do realizacji statycznego serwisu WWW.Opis obejmuje wykorzystanie kontenerów do stworzenia hermetycznego...",
    "content": "W poradniku pokazano jak wykorzystać konteneryzację i wsparcie dla niej w Visual Studio Code do realizacji statycznego serwisu WWW.Opis obejmuje wykorzystanie kontenerów do stworzenia hermetycznego i przenośnego środowiska pracyoraz hosting lokalny i z użyciem GitHub.Przedstawiona metoda lokalnego hostingu umożliwia dostęp do serwisu za pomocą bezpiecznego protokołu HTTPS i umożliwia korzystanie z usług dynamicznego rozwiązywania nazw gdy adres IP zrealizowanego serwera jest zmienny.Czynności wstępnePraktyczna realizacja porad wymaga zainstalowania Git, Docker‘a w wersji desktop lub serwer i Code oraz posiadania kont na GitHub i opcjonalnie DuckDNS.Przygotowanie folderu projektu  Utwórz puste repozytorium GitHub.Repozytorium będzie wykorzystywane do przechowywania plików generatora Hugo oraz plików źródłowych.Jeżeli konto GitHub ma być wykorzystywane również do publikacji gotowego serwisu oraz automatycznej generacji stron po aktualizacji zawartości serwisu, to powinno być ustawione jako publiczne. W kontach prywatnych funkcjonalności te są dostępne tylko za opłatą.  Sklonuj repozytorium do lokalnego folderu.Procedura klonowania zapewnia, że katalog projektu jest już w zasadzie zainicjowany jako repozytorium Git, tzn. istnieje podkatalog .git/ zawierający niezbędne metadane.W trakcie pracy nad serwisem zawartość katalogu projektu będzie podlegała zmianom.Utrzymanie synchronizmu z repozytorium GitHub wymaga nadążnej aktualizacji lokalnego folderu ze zmianami jakie zaszły w zdalnym repozytorium (git fetch) oraz okresowego wypychania zmian naniesionych lokalnie do zdalnego repozytorium (git stage, git commit, git push). Działania te będą wykonywane półautomatycznie przez VS Code.Jednak poprawne działanie klienta Git wymaga przypisania do lokalnego repozytorium pseudonimu i adresu email użytkownika, który nanosi w nim zmiany.Dlatego w katalogu projektu po jego utworzeniu należy wydać komendygit config user.name \"your_name\"git config user.email \"your_mail@somewhere.com\"  Zainstaluj kontener deweloperski zawierający gotowe środowisko pracy.Edytor Code umożliwia korzystanie z kontenerów Docker’a zawierających gotowe i hermetyczne środowiska pracy.Mechanizm ten nazwano DevContainers.Code po uruchomieniu w katalogu odpowiednio skonfigurowanego projektu “wchodzi” do wnętrza kontenera, a katalog projektu jest mapowany na katalog roboczy wewnątrz kontenera.Dla dewelopera automatycznie wszystkie narzędzia zainstalowane w kontenerze stają się dostępne.Jednocześnie wprowadzone przez niego zmiany ograniczone są do plików projektu oraz plików kontenera, przy czym te drugie są ulotne i znikają po skasowaniu kontenera.Tylko zmiany naniesione w katalogu roboczym mają charakter trwały.Dla wielu typów projektów szablony środowisk pracy są już przygotowane i publicznie udostępnione.W omawianym przypadku wykorzystamy środowisko do pracy ze statycznym generatorem stron o nazwie Hugo.Jest to jeden z najlepszych generatorów tego typu.W tym celu należy z podkatalogu containers/hugo repozytorium https://github.com/microsoft/vscode-dev-containers/ pobrać wraz zawartością katalog .devcontainer/ i opcjonalnie .vscode/.Zadanie to realizuje komendacurl -Ls https://github.com/microsoft/vscode-dev-containers/archive/main.tar.gz | tar -xvz --strip-components=3 --wildcards '*/*/hugo/.*'Ze względu na niewielką liczbe importowanych plików zadanie to można wykonać “ręcznie” z użyciem przeglądarki WWW.Opisane wyżej zadania realizuje poniższy skrypt#!/bin/shgh_user=your_gh_accountgh_repo=your_gh_repogh_name=your_namegh_mail=your_mail@somewhere.comgit clone https://github.com/${gh_user}/${gh_repo}cd ${gh_repo}git config user.name \"${gh_name}\"git config user.email \"${gh_mail}\"curl -Ls https://github.com/microsoft/vscode-dev-containers/archive/main.tar.gz | tar -xvz --strip-components=3 --wildcards '*/*/hugo/.*'Przed pierwszym uruchomieniem warto zapoznać się z treścią plików .devcontainer/devcontainer.json i .devcontainer/Dockerfile, które definiują konfigurację kontenera i przepis na jego zbudowanie.Zmiany w pliku Dockerfile zazwyczaj nie są konieczne.Natomiast w devcontainer.json warto ustawić wersję Hugo na extended, wersję node na najwyższą wspieraną w Dockerfile, ustawić nazwę kontenera korzystając z runArgs, poprosić o wypisanie w terminalu wersji zainstalowanych narzędzi po utworzeniu kontenera, zmienić rozszerzenie wykorzystywane do obsługi plików TOML z bungcip.better-toml na tamasfe.even-better-toml, dołożyć sprawdzanie pisowni i opcjonalnie dodać rozszerzenie do parsowania plików definiujących GitHub Actions (więcej o tym później).Po wspomnianych modyfikacjach plik devcontainer.json przyjmie postać{\t\"name\": \"Hugo (Community)\",\t\"build\": {\t\t\"dockerfile\": \"Dockerfile\",\t\t\"args\": {\t\t\t\"VARIANT\": \"hugo_extended\",\t\t\t\"VERSION\": \"latest\",\t\t\t\"NODE_VERSION\": \"18\"\t\t}\t},\t\"runArgs\": [\"--name=this-is-Hugo-DevContainer\"] ,\t\"customizations\": {\t\t\"vscode\": {\t\t\t\"settings\": { \t\t\t\t\"html.format.templating\": true,\t\t\t\t\"cSpell.language\": \"en, pl\",\t\t\t\t\"cSpell.userWords\": [\"tutaj\", \"wpisz\", \"wyjątki\", \"dla\", \"słów\", \"polskich\"]\t\t\t\t\t\t},\t\t\t\"extensions\": [\t\t\t\t\"tamasfe.even-better-toml\",\t\t\t\t\"davidanson.vscode-markdownlint\",\t\t\t\t\"streetsidesoftware.code-spell-checker-polish\",\t\t\t\t\"GitHub.vscode-github-actions\"\t\t\t]\t\t\t  \t\t}\t},\t\"forwardPorts\": [\t\t1313\t],\t\"postCreateCommand\": \"uname -a &amp;&amp; hugo version &amp;&amp; node --version\",\t\"remoteUser\": \"node\"}Teraz można uruchomić Code wydając w katalogu projektu komendęcode .Code “zauważy”, że istnieje podkatalog .devcontainer/ i zapyta, czy otworzyć projekt w kontenerze deweloperskim.Należy się na to zgodzić.Przełączenie pomiędzy pracą lokalną a kontenerem (traktowanym przez Code jak zdalna maszyna) aktywuje się za pomocą przycisku znajdującego się w lewym dolnym rogu interfejsu Code .Przygotowanie szablonu serwisuPo uruchomieniu Code i wejściu do wnętrza kontenera (pierwsze uruchomienie nie jest natychmiastowe, gdyż kontener musi zostać zbudowany z komponentów pobieranych z sieci) należy uruchomić terminal (‘Ctrl-Shift-`’) i zainicjować pusty serwishugo new site . --forcePraca z tak przygotowanym środowiskiem wymaga znacznego nakładu pracy i znajomości zasad generacji stron oraz przygotowanie szablonów HTML, które będą wypełniane treścią podczas generacji serwisu.Na szczęście można skorzystać z szablonów serwisów przygotowanych przez ochotników i udostępnionych na https://themes.gohugo.io/themes/.W dalszej części wykorzystamy szablon Fuji.Jego instalacja sprowadza się do wydania w katalogu projektu komendygit submodule add https://github.com/dsrkafuu/hugo-theme-fuji.git themes/fujiWszystkie prawidłowo przygotowane style serwisów zawierają gotowy przykład.Wystarczy go przenieść do budowanego serwisu, aby sprawdzić działanie przygotowanego środowiska pracycp -r themes/fuji/exampleSite/* .Plik konfiguracyjny obecnej wersji Hugo nosi nazwę hugo.toml.Wiele szablonów korzysta ze starszej konwencji i opiera się o plik config.toml.Na szczęście zachowana jest kompatybilność wstecz, więc wystarczy skasować hugo.toml.rm hugo.tomlNa obecnym etapie można już wygenerować serwis wydaną w terminalu komendąhugo server --disableFastRender --buildDraftsTak uruchomiony generator będzie śledził zmiany w plikach wejściowych i “na bieżąco” generował zawartość serwisu.Po wydaniu powyższej komendyCode zaproponuje podgląd serwisu w przeglądarce systemowej lub wbudowanej w Code.Więcej informacji na temat dostepnych przełączników mozna uzyskać komendąhugo server --helpPrzygotowanie treści serwisuZadaniem generatora Hugo jest przekształcenie zbioru plików wejściowych w formacie Markdown w gotowy serwis WWW.Translacja Markdown na HTML odbywa się zgodne z szablonami zdefiniowanymi w stylu serwisu.Hugo wymaga, aby pliki źródłowe były umieszczone w katalogu content/.Są one pogrupowane w zależności od typu informacji zamieszczonej w serwisie.Rodzaje publikowanych informacji są zdefiniowane w ramach stylu, natomiast prawie zawsze występuje typ post/ reprezentujący wpis blogu.Każdy plik wejściowy jest opatrzony metadanymi zawierającymi tytuł, datę utworzenia itp.Sposób formatowania tych metadanych zawierają pliki zaimportowane z przykładowego serwisu.W kontekście dalszej pracy istotna jest flaga draft---...draft: true---Pliki z tą flagą są wyłączane z zawartości serwisu przeznaczonego do publikacji.Zatem, aby uniknąć publikacji zaimportowanych przykładowych plików należy w każdym z nich ustawić tę flagę.Kolejnym elementem, którego edycja jest niezbędna, jest plik config.toml.Należy w nim ustawić URL pod którym będzie dostępny serwis.Jeżeli wartość zmiennej baseURL jest ustawiona nabaseURL = \"https://your_gh_account.github.io/gh_repo/\"to podgląd generowanych na bieżąco stron będzie dostępny pod adresemhttp://localhost:1313/gh_repo.Plik konfiguracyjny zawiera również wiele innych zmiennych, których nazwy i wartości silnie zależą od użytego stylu serwisu.Ostatnim z obowiązkowych kroków jest przygotowanie nowego wpisu.Przyjmiemy konwencję, że każdy post będzie zlokalizowany w osobnym folderze.W folderze tym będą również składowane zasoby skojarzone z postem, takie jak np. grafika.Nowy post zakłada się komendąhugo new post/to-moj-pierwszy-wpis/index.mdPlik index.md zawiera już niektóre metadane.Szablon wg którego został przygotowany znajduje się w pliku archetypes/default.md.Domyślnie plik index.md ma postać---title: \"To Moj Pierwszy Wpis\"date: 2023-08-05T17:18:23Zdraft: true---Plik ten należy uzupełnić treścią.Przy formatowaniu wpisu (treść, metadane) najlepiej kierować się przykładami zawartymi w szablonie serwisu.W niektórych szablonach streszczenia nowych wpisów pojawiają się na stronie głównej serwisu.Streszczenie oddziela się od treści głównej umieszczając w pliku wejściowym Markdown znacznik read more.Więcej informacji nt. prawidłowego przygotowania plików dla generatora jest dostępnych na stronie projektu Hugo.Przykłady zawarte w użytym szablonie serwisu również mogą być pomocne.Praca ze zdalnym repozytoriumZdalne repozytorium GitHub może wykorzystać trojako: do synchronizacji katalogów roboczych na kilku różnych komputerach, do stworzenia kopii zapasowej projektu oraz do automatycznego generowania serwisu i jego publikacji. Ostatniemu zagadnieniu poświęcono osobną sekcję.Praca z repozytorium GitHub w Code nie nastręcza żadnych trudności bowiem w edytor wbudowano odpowiednie mechanizmy.Pliki, które zmieniono względem ostatniej synchronizacji ze zdalnym repozytorium są oznaczane literką “U”.Aby zsynchronizować się zdalnym repozytorium należy na panelu bocznym wybrać ikonę współdzielenia.Synchronizacja odbywa się w paczkach zwanych “Commit”.Każdy “Commit” jest opatrzony krótkim opisem, zatem mechanizm ten umożliwia aktualizację repozytorium w sposób zorientowany problemowo.Aby plik znalazł się w danej paczce “Commit”, musi najpierw zostać przeniesiony do poczekalni (tzw. stage).Po wybraniu ikony współdzielenia prezentowana jest lista zmienionych plików projektu.Z listy tej można wybrać pliki, które zostają wystawione do aktualizacji (stage).Następnie, w górnej linii panelu bocznego należy wpisać opis paczki, a następnie wybrać “Commit”.Paczek “Commit” można utworzyć kilka.Aktualizację ze zdalnym repozytorium realizuje wybranie przycisku “Sync”.Git umożliwia wyłączenie wybranych plików z mechanizmu synchronizacji. Są one określone w pliku .gitignore, przy czym dozwolone jest stosowanie standardowych masek powłoki w postaci znaków “?” i “*”.Typowa postać tego pliku dla repozytorium zawierające projekt statycznego serwisu Hugo ma postaćresources/_gen/*themes/*/exampleSite/*.vscode/public/*Katalog resources/ zawiera pliki pośrednie wykorzystane przez generator, natomiast katalog public/ pliki wynikowe.Jeżeli repozytorium GitHub ma być wykorzystane do publikacji gotowego serwisu wygenerowanego lokalnie, to oczywiście katalog public/ należy usunąć z pliku .gitignore.Publikacja serwisuSerwis GitHub, podobnie do GitLab i kilku innych serwisów wspierających pracę grupową nad projektami, dostarcza usługi publikacji zasobów repozytorium oraz możliwość ciągłej integracji zmian i dostarczania nowych wersji oprogramowania (CI/CD).W serwisie GitHub usługi te noszą odpowiednio nazwy GitHub Pages i GitHub Actions.GitHub Pages polega na potraktowaniu jednego z katalogów repozytorium jako serwisu WWW i udostępnienia go pod adresemhttps://your_gh_account.github.io/gh_repo/Z kolei za pomocą GitHub Actions można skonfigurować wyzwalanie pewnych działań na zawartości serwisu gdy zostaną spełnione określone warunki, np. gdy pliki repozytorium zostaną zaktualizowane.Pierwotnie usługi GitHub Pages i GitHub Actions funkcjonowały niezależnie.Jednym z dostępnych działań jest możliwość opublikowania określonego folderu repozytorium jako serwisu WWW.Obecnie GitHub Pages jest realizowana jako jedno z działań GitHub Actions, jednak, ze względów historycznych ma wydzieloną specjalną pozycję w interfejsie repozytorium.Poza konfiguracją mechanizmu CI/CD żadna dodatkowa konfiguracja nie jest potrzebna do publikacji serwisu.Należy jednak pamiętać, że usługi GitHub Actions i GitHub Pages są dostępne nieodpłatnie tylko dla repozytoriów publicznych.Dalej przedstawione zostaną trzy różne scenariusze publikacji serwisu wygenerowanego przez Hugo:  wersja A: w serwisie GitHub upublicznione są pliki wejściowe wejściowe w formacie Markdown oraz wzorce stanowiące podstawę generacji stron HTML. GitHub Actions są wykorzystywane do wygenerowania i opublikowania nowej wersji serwisu.  wersja B: w serwisie GitHub upublicznione są tylko pliki wynikowe, tj. zawartość wygenerowanego serwisu. GitHub Actions są wykorzystywane do jego publikacji.  wersja C: repozytorium GitHub jest wykorzystywane tylko do przechowywania plików wejściowych generatora i nie musi być upublicznione. Generacja zawartości zawartości serwisu i jej upublicznienie wykorzystuje lokalne zasoby użytkownika.A. GitHub ActionsDo publikacji serwisu zostanie wykorzystany automatyczne działanie, przy czym interfejs do jego konfiguracji znajduje się w menu Pageshttps://github.com/${gh_user}/${gh_repo}/settings/pagesJednak, aby publikacja się udała, w repozytorium musi istnieć gałąź Git o nazwie gh-pages.Można ją utworzyć w serwisie GitHub wybierając na stronie głównej repozytorium przycisk Branches i dodać wspomnianą gałąź.        Your browser does not support the video tag.  Dopiero teraz w menu Pages jako metodę publikacji należy wybrać GitHub Actions przy użyciu akcji Hugo.        Your browser does not support the video tag.  Takie działanie spowoduje powstanie w katalogu .github/workflows pliku hugo.yml o treściname: Deploy Hugo site to Pageson:  push:    branches: [\"main\"]  workflow_dispatch:permissions:  contents: read  pages: write  id-token: writeconcurrency:  group: \"pages\"  cancel-in-progress: falsedefaults:  run:    shell: bashjobs:  # Build job  build:    runs-on: ubuntu-latest    env:      HUGO_VERSION: 0.114.0    steps:      - name: Install Hugo CLI        run: |          wget -O $/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\          &amp;&amp; sudo dpkg -i $/hugo.deb      - name: Install Dart Sass        run: sudo snap install dart-sass      - name: Checkout        uses: actions/checkout@v3        with:          submodules: recursive      - name: Setup Pages        id: pages        uses: actions/configure-pages@v3      - name: Install Node.js dependencies        run: \"[[ -f package-lock.json || -f npm-shrinkwrap.json ]] &amp;&amp; npm ci || true\"      - name: Build with Hugo        env:          # For maximum backward compatibility with Hugo modules          HUGO_ENVIRONMENT: production          HUGO_ENV: production        run: |          hugo \\            --minify \\            --baseURL \"$/\"      - name: Upload artifact        uses: actions/upload-pages-artifact@v2        with:          path: ./public  # Deployment job  deploy:    environment:      name: github-pages      url: $    runs-on: ubuntu-latest    needs: build    steps:      - name: Deploy to GitHub Pages        id: deployment        uses: actions/deploy-pages@v2Sekcja on: tego pliku definiuje jakie zdarzenia aktywują akcję.W zamieszczonym przykładzie skonfigurowano dwa takie zdarzenia: aktualizacja gałęzi main (opcja push:) oraz manualną aktywację (workflow_dispatch:) za pomocą interfejsu serwisu GitHub.Późniejsza zmiana metody publikacji zawartości repozytorium wymaga wcześniejszego  całkowitego wyłączenia publikowania (unpublish).Biorąc pod uwagę, że skonfigurowana akcja zapewnia generację plików HTML, to synchronizacja plików z podkatalogu public nie jest konieczna.W tak skonfigurowanym repozytorium każdorazowa zmiana plików wejściowych powoduje zbudowanie serwisu.Takie postępowanie nie jest zbyt eleganckie, bowiem wiele z tych wywołań jest po prostu niepotrzebnych.Rozwiązaniem sytuacji jest utworzenie gałęzi devel i praca nad serwisem z jej wykorzystaniem.Do jej utworzenia można wykorzystać Code.Po wybraniu ikony synchronizacji wybieramy ... przy nazwie repozytorium, a następnie Branch-&gt; Create Branch i wpisujemy devel.Teraz utworzoną gałąź publikujemy (...-&gt;Branch-&gt;Publish Branch), co zapewni, że zostanie ona przeniesiona do drzewa Git znajdującego się w repozytorium GitHub.Synchronizacja z repozytorium GitHub jest “bezkosztowa” gdyż zgodnie z konfiguracją tylko zmiany w gałęzi main włączają budowę serwisu.    Your browser does not support the video tag.Dopiero gdy określony etap pracy zostanie osiągnięty, wtedy należy przełączyć się na gałąź main, włączyć do niej zmiany z gałęzi devel i zsynchronizować GitHub.Wtedy synchronizacja z serwisem GitHub spowoduje zbudowanie serwisu na mocy konfiguracji dyrektywy on:.Po wykonaniu synchronizacji aktywną gałąź w lokalnym repozytorium znowu należy przełączyć na devel.    Your browser does not support the video tag.Zaletą przedstawionej konfiguracji jest możliwość aktualizacji zawartości serwisu z dowolnego miejsca za pomocą przeglądarki internetowej z wykorzystaniem natywnego interfejsu usługi GitHub lub https://vscode.dev/.B. GitHub PagesMoże się zdarzyć, że jesteśmy zainteresowani tylko publikacją gotowego serwisu bez upubliczniania postaci źródłowej publikowanych stron.Idea takiej realizacji serwisu polega na utworzeniu w serwisie GitHub dwóch repozytoriów:  prywatnego, nie korzystającego z GitHub Actions czy GitHub Pages i zawierającego tylko pliki źródłowe wykorzystywane w procesie generacji,  publicznego. korzystającego z powyższych udogodnień i zawierającego tylko pliki wynikowe.Adaptacja poprzedniej konfiguracji do takiego wymogu jest stosunkowo prosta, należy jedynie pamiętać, żegenerator Hugo umieszcza pliki wynikowe w podkatalogu public:  w usłudze GitHub repozytorium przechowujące pliki źródłowe przekształcamy w prywatne,  w usłudze GitHub zakładamy nowe repozytorium, dalej będziemy się do niego odwoływać jako your_hugo_site,      w lokalnym repozytorium czyścimy podkatalog public (znaczek * jest ważny):    rm -rf public/*        a następnie podpinamy do niego nowo utworzone repozytorium    git submodule add https://github.com/${gh-user}/your_hugo_site public/      Code zauważy zmianę i dopasuje swój interfejs tak aby umożliwić pracę z dwoma repozytoriami jednocześnie.Publikacja wymaga istnienia w repozytorium gałęzi gh-pages.Można ją utworzyć w serwisie GitHub wybierając na stronie głównej repozytorium przycisk Branches.Po wybraniu ikony synchronizacji wybieramy ... przy nazwie repozytorium , a następnie Branch-&gt; Create Branch i wpisujemy gh-pages.        Your browser does not support the video tag.  Teraz w nowym repozytorium wystarczy aktywować mechanizm GitHub Pages.https://github.com/${gh_user}/${gh_repo}/settings/pagesTym razem należy wybrać działanie Static HTML (Build and deployment-&gt;GitHub Actions).Taki wybór spowoduje, że w repozytorium your_hugo_site zostanie utworzone działanie .github/workflows/static.ymlDomyślnie akcja publikacji dotyczy zawartości całego repozytorium, nie trzeba zatem nic zmieniać.name: Deploy static content to Pageson:  push:    branches: [\"main\"]  workflow_dispatch:permissions:  contents: read  pages: write  id-token: writeconcurrency:  group: \"pages\"  cancel-in-progress: falsejobs:  deploy:    environment:      name: github-pages      url: $    runs-on: ubuntu-latest    steps:      - name: Checkout        uses: actions/checkout@v3      - name: Setup Pages        uses: actions/configure-pages@v3      - name: Upload artifact        uses: actions/upload-pages-artifact@v2        with:          # Upload only 'public/' folder          path: '.'      - name: Deploy to GitHub Pages        id: deployment        uses: actions/deploy-pages@v2Praca w tak przygotowanym środowisku przebiega wg następującego cyklu:  Korzystając z Code tworzymy lokalnie nową zawartość serwisu. Podgląd on-line pozwala na ocenę, czy nowo utworzone treści nadają się do publikacji. Gdy to jest konieczne wykonujemy synchronizację z repozytorium prywatnym.      Gdy tak jest, w gotowych do publikacji materiałach ustawiamy draft: false i generujemy nową postać serwisu komendą    hugo --minify         Takie działanie spowoduje aktualizację zawartości katalogu public/ i konieczność synchronizacji ze zdalnym repozytorium. Po jej wykonaniu skonfigurowana akcja GitHub automatycznie opublikuje nową postać serwisu. Należy jedynie pamiętać, że wykonywanie akcji może nie być natychmiastowe i może chwilę potrwać.W przedstawionej konfiguracji można zachować prywatność danych wejściowych. Ceną jest komplikacja schematu pracy nad serwisem.C. Własny hosting serwisuW niniejszym punkcie opisano działania niezbędne do lokalnego hostingu tworzonego serwisu.Do jego realizacji potrzebna będzie maszyna z publicznym (routowalnym) adresem IP. Nie ma wymogu aby adres ten był stały.  Maszyna musi mieć skonfigurowany dostęp za pomocą protokołu SSH. Do hostingu wykorzystane zostaną kontenery Docker, zatem również konieczna jest instalacja tego serwera na maszynie publikującej serwis WWW.Nic nie stoi na przeszkodzie, aby maszyna wykorzystana do publikacji była zrealizowana jako wirtualny host w chmurze.Serwis WWW musi mieć swoją nazwę, zatem należy wykupić domenę lub skorzystać z darmowych odmian dynamicznych serwisów DNS do skojarzenia nazwy serwisu z adresem IP maszyny udostępniającej serwis.W prezentowanym dalej przykładzie zostanie wykorzystana usługa DuckDNS.Do realizacji lokalnego hostingu jakiekolwiek serwisu niezbędny jest routowalny (publiczny) adres IP.W omawianej konfiguracji przyjęto założenie, że adres ten jest przypisany do routera z usługą NAT, natomiast host realizujący serwis znajduje się w sieci lokalnej “schowanej” za routerem i korzystającej nieroutowalnych (prywatnych) adresów IP.Przyjęto również założenie, że host, na którym rozwijany jest serwis i na którym zainstalowano Code, znajduje się w tej samej sieci co host z serwisem WWW.Na hoście z serwisem WWW działa serwer SSH.Do publicznego adresu IP musi być przypisana kwalifikowana domenowa nazwa hosta (FQDN) w formacie nazwa.serwisu.moja.domena.org.Jeżeli adres IP jest stały, to wystarczy wykupić dla niego domenę.Dla adresów zmiennych konieczne jest skorzystanie z usługi dynamicznego DNS.Idea działania takiej usługi polega na tym, że host o zmiennym adresie IP otrzymuje identyfikator unikalny w ramach dynamicznego serwisu DNS i co pewien czas “melduje” swój adres IP.Usługa dynamicznego DNS rozpowszechnia tę informację, komunikując się z innymi serwisami DNS, które aktualizują swoją konfigurację.Oczywiście, dla stałych adresów IP skorzystanie z usługi dynamicznego DNS do uzyskania nazwy domenowej jest również możliwe.Darmowe usługi dynamicznego DNS pozwalają zazwyczaj tylko na określenie nazwy hosta, a  domenowa część nazwy jest zadana przez dostawcę serwisu.Zaproponowana konfiguracja hosta realizującego serwis pozwala na prowadzenie wielu serwisów WWW na tym samym adresie IP, jednak o różnych nazwach domenowych.Oczywiście nic nie stoi na przeszkodzie, aby do tego samego numeru IP przypisać wiele nazw domenowych.Dalej do skojarzenia adresu IP z nazwą domenową wykorzystany darmowy serwis https://duckdns.org.W serwisie należy założyć konto.W ramach każdego konta można nieodpłatnie założyć kilka domen (wraz z subdomenami).Każdy użytkownik serwisu ma przypisany unikalny token, który jest wykorzystywany do aktualizacji zmiennego adresu IP.Na hoście, który ma utrzymywać serwis www konieczna jest instalacja serwera Dockera.Użytkownik zdalnego hosta powinien być dodany do grupy docker, co uwolnia od konieczności pracy z Dockerem na prawach administratora.sudo usermod -aG docker ${USER}Aby powyższa zmiana odniosła skutek, należy się wylogować i zalogować lub w otwartych sesjach wydać komendęnewgrp dockerW zdalnym zarządzaniu kontenerami dobrze spisuje się Portainer.Uboższa jego wersja jest dostępna nieodpłatnie.Instalacja sprowadza się do dwóch komenddocker volume create portainer_datadocker run -d -p 8000:8000 -p 9000:9000 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latestOd teraz zainstalowanymi obrazami i kontenerami można zarządzać łącząc się przeglądarką przy użyciu protokołu HTTP z portem 9000 hosta z Portainerem.Instalacja własnego serwisu WWW jest bardzo prosta.Do katalogu services hostamkdir -p /home/your_host_account/services/cd /home/your_host_account/services/wgrywamy plik docker-compose.yml o następującej treściversion: \"3\"networks:  frontend:    name: dmzservices:  duckdns:    image: lscr.io/linuxserver/duckdns:latest    container_name: dmz-duckdns    environment:      - PUID=1000 #optional      - PGID=1000 #optional      - TZ=Europe/Warsaw      - SUBDOMAINS=misiek,kociak      - TOKEN=xxxxxxxx-yyyy-zzzz-aaaa-bbbbbbbbbbbb      - LOG_FILE=true #optional    volumes:      - /home/your_host_account/services/duckdns:/config #optional    networks:     - frontend    restart: unless-stopped  nginxproxy:    image: 'jc21/nginx-proxy-manager:latest'    container_name: dmz-nginxproxy    restart: unless-stopped    ports:      - '8888:80'      - '81:81'      - '4443:443'    volumes:      - /home/your_host_account/services/npm/data:/data      - /home/your_host_account/services/npm/letsencrypt:/etc/letsencrypt    networks:      - frontend  www0:    image: lscr.io/linuxserver/nginx:latest    container_name: dmz-www0    environment:      - PUID=1000      - PGID=1000      - TZ=Europe/London    volumes:      - /home/your_host_account/services/www0:/config    restart: unless-stopped    networks:      - frontend  www1:    image: lscr.io/linuxserver/nginx:latest    container_name: dmz-www1    environment:      - PUID=1000      - PGID=1000      - TZ=Europe/London    volumes:      - /home/your_host_account/services/www1:/config    restart: unless-stopped    networks:      - frontendNastępnie należy utworzyć puste katalogi, w których będą przechowywane dane z kontenerówmkdir -p {duckdns,npm/data,npm/letsencrypt,www0,www1}Ostateczne uruchomienie stosu usług realizuje komendadocker compose up -dwydana w katalogu z plikiem docker-compose.yml.Kontener duckdns odpowiada za aktualizację adresu IP serwisu w usłudze dynamicznego DNS.Kontener nginx-proxy-manager realizuje reverse-proxy, za którym schowane są serwisy www0 i www1.Kontener ten również troszczy się o utrzymanie aktualnego certyfikatu dla domen skonfigurowanych w ramach proxy.Zarządzanie proxy (i domenami) realizuje się za pomocą interfejsu WWW dostępnego na porcie 81.Interfejsy http i https zarządzanych usług dostępne są odpowiednio na portach 8888 i 4443 dlatego na routerze realizującym NAT należy uaktywnić Port Forwarding i zrealizować przypisanie “80-&gt;ip_host:8888”, “443-&gt;ip_host:4443”.W ten sposób ruch docierający do routera i skojarzony z protokołami http i https zostanie przekierowany do usługi proxy, a ta, na podstawie nazwy domenowej, podejmie decyzję do którego serwisu WWW ruch powinien być skierowany.Wspomniane przekierowanie portów w routerze musi być wykonane przed konfiguracją proxy, bowiem są one wykorzystywane do komunikacji z serwisem LetsEncrypt w celu uzyskania certyfikatów SSL.Konfiguracja Nginx Proxy Manager jest stosunkowo prosta.Pierwsze łączenie z interfejsem administracyjnym (port 81) wymaga zmiany hasła i nazwy użytkownika (domyślnymi wartościami są admin i changeme).Konfigurację rozpoczynamy od uzyskania certyfikatów dla skonfigurowanych domen (Dashboard-&gt;SSL Certificates).Następnie dodajemy Proxy Hosts. Jako nazwę Forward Hostname należy podać nazwę kontenera,czyli w rozważanym przypadku dmz-www0 lub dmz-www1.Środowisko do prezentacji zawartości serwisu jest już przygotowane.Należy jedynie pamiętać, aby w konfiguracji Hugo (config.toml) również ustawić nazwę skonfigurowaną w DuckDNS.Serwis generuje się jak zwykle, zatrzymując serwer i wydając w katalogu projektu komendęhugoWystarczy teraz przesłać zawartość katalogu public/ do katalogu głównego serwera WWW tj.scp -r public/* user@ip_host_lan:/home/your_host_account/services/www1/www/i serwis jest opublikowany.PodsumowaniePrzedstawione scenariusze wykorzystania Code do pracy nad serwisem WWW nie wyczerpują wszystkich możliwości.Bezpośrednia praca nad plikami zapisanymi w zdalnym repozytorium GitHub jest możliwa tylko przy użyciu przeglądarki.Interfejs imitujący Code i zapewniający nieco zubożoną funkcjonalność jest dostepny pod adresem https://vscode.dev.Jedną z takich brakujących funkcjonalności jest praca we własnym kontenerze.Jednak nie oznacza to, że jest to niemożliwe.Wystarczy sobie uświadomić, że kontenery Docker‘a traktowane są jak zdalne maszyny.W ramach usługi GitHub można do tego wykorzystać funkcję Codespaces dostępną w głównym menu użytkownika.Usługa to pozwala na utworzenie w chmurze wirtualnych maszyn na których uruchomione jest to samo oprogramowanie które umożliwiają komunikację z kontenerem.Jako interfejs użytkownika jest wykorzystywany https://vscode.dev, co oznacza, że do pracy z taką zdalną maszyną wystarczy przeglądarka.Należy jednak pamiętać, że Codespaces nie są całkowicie bezpłatne.Istnieją limity zasobów, które można w zadanym okresie czasu wykorzystać za darmo.Potrzeby powyżej limitów określonych przez dostawcę usługi wymagają wniesienia opłat."
  }
  
]

